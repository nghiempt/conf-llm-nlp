{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file id:  file-Ru1c5UJwxwCNVKBkze8I3I6F\n"
     ]
    }
   ],
   "source": [
    "# Upload Training and Validation Files\n",
    "training_file = client.files.create(\n",
    "    file=open(\"data.jsonl\", \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "print(\"Training file id: \", training_file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-9Rp36wVMvyizIpqtaFurkCW1', created_at=1727878288, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-uXFhRQZlPYdmwJvwmyYmTROo', result_files=[], seed=534979875, status='validating_files', trained_tokens=None, training_file='file-Ru1c5UJwxwCNVKBkze8I3I6F', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='llm')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create Fine-Tuning Job\n",
    "suffix_name = \"llm\"\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file='file-Ru1c5UJwxwCNVKBkze8I3I6F',\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    suffix=suffix_name,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Finetuning jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-9Rp36wVMvyizIpqtaFurkCW1', created_at=1727878288, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:imutably-oy:llm:ADudBVBQ', finished_at=1727879315, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-uXFhRQZlPYdmwJvwmyYmTROo', result_files=['file-E8uZSc8IGReo70k5bIaSvbWJ'], seed=534979875, status='succeeded', trained_tokens=335838, training_file='file-Ru1c5UJwxwCNVKBkze8I3I6F', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='llm')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(\"ftjob-9Rp36wVMvyizIpqtaFurkCW1\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine tuned model id:  ft:gpt-3.5-turbo-0125:imutably-oy:llm:ADudBVBQ\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print('\\nFine tuned model id: ', fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use FineTuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import aiohttp\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Lớp HANDLER để xử lý dữ liệu\n",
    "class HANDLER:\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_json(json_file):\n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            # Tạo danh sách các prompt mà không có role là \"assistant\"\n",
    "            prompts = []\n",
    "            for entry in data:\n",
    "                prompt_parts = []\n",
    "                for message in entry.get(\"messages\", []):\n",
    "                    if message.get(\"role\") != \"assistant\":  # Bỏ qua vai trò 'assistant'\n",
    "                        prompt_parts.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "                \n",
    "                if prompt_parts:\n",
    "                    prompts.append(prompt_parts)  # Lưu lại các prompt không có 'assistant'\n",
    "\n",
    "            return prompts\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            return \"File not found. Please check the file path.\"\n",
    "        except json.JSONDecodeError:\n",
    "            return \"Error decoding JSON. Please check the file format.\"\n",
    "    \n",
    "    @staticmethod\n",
    "    async def call_api_teacher(prompt):\n",
    "        url = \"https://api.openai.com/v1/chat/completions\"\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {os.getenv('OPENAI_API_KEY')}\",  # Use OpenAI API key\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        # Payload for OpenAI's GPT model\n",
    "        payload = json.dumps({\n",
    "            \"model\": \"ft:gpt-3.5-turbo-0125:imutably-oy:llm:ADudBVBQ\", \n",
    "            \"temperature\": 0.5,  # Optional: adjust the temperature for creativity\n",
    "            \"messages\": prompt\n",
    "        })\n",
    "\n",
    "        # Sending the POST request using aiohttp\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.post(url, headers=headers, data=payload) as response:\n",
    "                # Check if the response content type is JSON\n",
    "                if response.headers['Content-Type'] == 'application/json':\n",
    "                    response_json = await response.json()\n",
    "                    if 'error' in response_json:\n",
    "                        return f\"Error: {response_json['error']}\"\n",
    "                    \n",
    "                    # Extracting the content from the message in choices array\n",
    "                    content = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "                    return content\n",
    "                else:\n",
    "                    # If not JSON, read the response as text\n",
    "                    response_text = await response.text()\n",
    "                    return f\"Unexpected response: {response_text}\"\n",
    "\n",
    "    @staticmethod\n",
    "    async def loop_json(input_json_path, output_json_path):\n",
    "        # Đọc file JSON và xử lý các prompt\n",
    "        prompts = HANDLER.process_json(input_json_path)\n",
    "        \n",
    "        results = []  # Danh sách để lưu trữ kết quả\n",
    "        \n",
    "        for index, prompt in enumerate(prompts):\n",
    "            print(f\"\\n_____________ Processing Prompt {index + 1} _____________\")\n",
    "            \n",
    "            # Gọi API bất đồng bộ với prompt\n",
    "            assistant_reply = await HANDLER.call_api_teacher(prompt)\n",
    "            \n",
    "            # Kiểm tra lỗi từ phản hồi API và lưu lại kết quả\n",
    "            result_entry = {\n",
    "                \"prompt_index\": index + 1,\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": assistant_reply if \"Error\" not in assistant_reply else \"Error\"\n",
    "            }\n",
    "            \n",
    "            # Thêm kết quả vào danh sách\n",
    "            results.append(result_entry)\n",
    "            \n",
    "            print(f\"~~~~~~~~~~~~~~ Success for Prompt {index + 1} ~~~~~~~~~~~~~~\\n\")\n",
    "        \n",
    "        # Lưu toàn bộ kết quả vào file JSON khi hoàn tất\n",
    "        with open(output_json_path, 'w', encoding='utf-8') as output_file:\n",
    "            json.dump(results, output_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_____________ Processing Prompt 1 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 1 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 2 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 2 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 3 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 3 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 4 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 4 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 5 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 5 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 6 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 6 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 7 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 7 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 8 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 8 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 9 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 9 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 10 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 10 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 11 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 11 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 12 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 12 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 13 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 13 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 14 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 14 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 15 _____________\n",
      "~~~~~~~~~~~~~~ Success for Prompt 15 ~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "_____________ Processing Prompt 16 _____________\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "async def main():\n",
    "    load_dotenv() \n",
    "    input_json_path = \"../data/phase-02/100-test.json\" \n",
    "    output_json_path = \"../output/phase-01/output-teacher.json\"\n",
    "    await HANDLER().loop_json(input_json_path, output_json_path)\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
